= KKT Conditions =
:doctype: book
:stem: latexmath
:eqnums:
:toc:

== Optimality Conditions ==
We know that if stem:[\mathbf{x}^*] is an optimal solution, then the necessary condition is that

[stem]
++++
\nabla f(\mathbf{x}^*)^\top (\mathbf{x}-\mathbf{x}^*) \geq 0 \hspace{1cm} \forall \mathbf{x} \in \mathcal{N}_{\delta}(\mathbf{x}^*) \cap F
++++

As a special case, when stem:[F] is an open set or when there is no any restriction in the directions, the above condition can be equivalently written as

[stem]
++++
\nabla f(\mathbf{x}^*) = \mathbf{0}
++++

But, if stem:[F] is a complicated set, only stem:[\mathbf{x}^*]'s that satisfy the first condition will be our potential optimal points. Typically it is difficult to evaluate the first condition. This condition can be broken down and can be written in a convenient way. Those equivalent conditions are known as the *KKT conditions*.

The KKT conditions are necessary, but they are not sufficient for optimality. However, on doing further checks such as the positive definiteness of the Hessian matrix, convexity, etc. at the points where the KKT conditions are satisfied, then we can conclude if the point is a local minima, local maxima, saddle, global minima, or global maxima.

== KKT Conditions ==

For the given MP, write the Lagrangian function stem:[\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})]. The dual MP formulation is given by

[stem]
++++
\max_{\lambda_i \geq 0 \, \forall i} \min_{\mathbf{x} \in D} f(\mathbf{x}) + \sum_{i=1}^m  \lambda_i g_i(\mathbf{x}) = \max_{\lambda_i \geq 0 \, \forall i} \min_{\mathbf{x} \in D} \mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})
++++

. If stem:[\mathbf{x}^*] and stem:[\boldsymbol{\lambda}^*] are optimal solutions, then they should be feasible solutions. That is
+
[stem]
++++
\mathbf{x}^* \in D, g_i(\mathbf{x}^*) \leq 0 \,\, \forall i, \boldsymbol{\lambda}^* \geq \mathbf{0}
++++
+
This is known as the feasibility condition.

. stem:[\lambda_i^* g_i(\mathbf{x}^*) = 0 \, \forall i]
+
We know that the primal MP can be written as (refer to the lagrange_duality article for more details). The second term is the indicator function.
+
[stem]
++++
\min_{\mathbf{x} \in D} f(\mathbf{x}) + \sum_{i=1}^m \max_{\lambda_i \geq 0} \lambda_i g_i(\mathbf{x})
++++
+
* If stem:[g_i(\mathbf{x}) < 0], then stem:[\lambda_i] should be 0 (because that is where the indicator function MP is maximized). Then,stem:[\lambda_i g_i(\mathbf{x})] will be 0.
* If stem:[g_i(\mathbf{x}) = 0], then stem:[\lambda_i g_i(\mathbf{x})] will always be 0.
+
So, in both cases, stem:[\lambda_i^* g_i(\mathbf{x}^*)] is always 0. This is known as the complementary slackness condition.

. Assuming stem:[D] is an open set, if stem:[\mathbf{x}^*] is an optimal solution of the inner MP, then the gradient of the Lagrangian function with respect to stem:[\mathbf{x}] should be stem:[\mathbf{0}] at stem:[(\mathbf{x}^*, \boldsymbol{\lambda}^*)].
+
[stem]
++++
\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}^*, \boldsymbol{\lambda}^*) = \mathbf{0}
++++
+
This is the gradient condition.

These three conditions are known as the KKT conditions. KKT conditions are necessary and sufficient for regular convex programs.

== Examples ==

*Example 01:*

Consider the following MP

[stem]
++++
\begin{align*}
\min_{\mathbf{x} \in \mathbb{R}^n} & \hspace{1cm} \mathbf{x}^\top\mathbf{Ax} \\
& \text{ s.t. }  \mathbf{x}^\top\mathbf{Bx} \leq 1
\end{align*}
++++

where stem:[\mathbf{A}, \mathbf{B}] are positive semi-definite matrices. This is the problem of minimization of a quadratic over an ellipse.

The Lagrangian function is stem:[\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda}) = \mathbf{x}^\top\mathbf{Ax} + \lambda (\mathbf{x}^\top\mathbf{Bx} - 1) ]. The KKT conditions for the optimality are

. Feasibility condition:
+
[stem]
++++
\mathbf{x} \in \mathbb{R}^n, \mathbf{x}^\top\mathbf{Bx} \leq 1, \lambda \geq 0
++++

. Complementary slackness: stem:[\lambda (\mathbf{x}^\top\mathbf{Bx} - 1) = 0]
. Gradient condition: stem:[\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \lambda) = \mathbf{0} ]

By the product rule, we know that

[stem]
++++
\begin{align*}
d(\mathbf{x}^\top \mathbf{Ax}) & = (d\mathbf{x}^\top) \mathbf{Ax} + \mathbf{x}^\top \mathbf{A} (d\mathbf{x}) \\
& = (\mathbf{Ax})^\top d\mathbf{x} + \mathbf{x}^\top \mathbf{A} d\mathbf{x} \\
& = \mathbf{x}^\top \mathbf{A}^\top d\mathbf{x} + \mathbf{x}^\top \mathbf{A} d\mathbf{x} \\
& = \mathbf{x}^\top (\mathbf{A}^\top + \mathbf{A}) d\mathbf{x}
\end{align*}
++++

Thus, stem:[\nabla_{\mathbf{x}} (\mathbf{x}^\top \mathbf{Ax}) =  (\mathbf{A} + \mathbf{A}^\top) \mathbf{x} = 2\mathbf{Ax}] as stem:[\mathbf{A}] is symmetric. Therefore

[stem]
++++
\begin{align*}
\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \lambda) & = \mathbf{0} \\
2\mathbf{Ax} + 2 \lambda \mathbf{Bx} & = \mathbf{0} \\
 \iff (\mathbf{A} + \lambda \mathbf{B}) \mathbf{x} & = \mathbf{0}
\end{align*}
++++

The equation stem:[(\mathbf{A} + \lambda \mathbf{B}) \mathbf{x} = \mathbf{0}] denotes the null space of the matrix stem:[\mathbf{A} + \lambda \mathbf{B}].

* If the matrix stem:[\mathbf{A} + \lambda \mathbf{B}] is not rank-deficient, then stem:[\mathbf{x} = \mathbf{0}] is the only solution. Then, this implies stem:[\lambda=0] (from the complementary slackness condition). This point satisfies all the KKT conditions. And since the matrix stem:[\mathbf{A}] is positive semi-definite, i.e., stem:[\mathbf{x}^\top\mathbf{Ax} \geq 0 \,\, \forall \mathbf{x} \in \mathbb{R}^n], we can easily verify that this is a valid optimal solution. Therefore, stem:[\mathbf{x}^* = \mathbf{0}] and stem:[\lambda^*=0].

* If the matrix stem:[\mathbf{A} + \lambda \mathbf{B}] is rank-deficient, we can also get non-zero stem:[\mathbf{x}] as optimal solutions. Such stem:[\mathbf{x}]'s will be in the null space of stem:[\mathbf{A} + \lambda \mathbf{B}].

*Example 02:*

Consider the following MP

[stem]
++++
\begin{align*}
\min_{\mathbf{x} \in \mathbb{R}^n} & \hspace{1cm} \frac{1}{2} \mathbf{x}^\top\mathbf{Px} + \mathbf{q}^\top \mathbf{x} + r \\
& \text{ s.t. }  |x_i| \leq 1 \,\, \forall i
\end{align*}
++++

The constraint can also be written as stem:[x_i \leq 1] and stem:[-x_i \leq 1]. The Lagrangian function is

[stem]
++++
\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = \frac{1}{2} \mathbf{x}^\top\mathbf{Px} + \mathbf{q}^\top \mathbf{x} + r + \sum_{i=1}^n \lambda_i (x_i -1) + \sum_{i=1}^n \mu_i (-x_i -1) 
++++

The KKT conditions are

. stem:[\mathbf{x} \in \mathbb{R}^n, |x_i| \leq 1, \lambda_i \geq 0, \mu_i \geq 0 \,\,\, \forall i].
. stem:[\lambda_i (x_i -1)= 0], stem:[\mu_i (-x_i -1) = 0]
. stem:[\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = \mathbf{0} \implies \mathbf{Px} + \mathbf{q} + \boldsymbol{\lambda} - \boldsymbol{\mu} = \mathbf{0}]. If stem:[\mathbf{P}] is invertible, stem:[\mathbf{x} = \mathbf{P}^{-1}(\mathbf{q} - \boldsymbol{\lambda} + \boldsymbol{\mu})].

Is there a solution stem:[\mathbf{x}] where the constraints are not active at all, i.e., that is for stem:[|x_i| < 1 \,\, \forall i]? If there was such a solution, then stem:[\lambda_i, \mu_i = 0 \,\, \forall i] (from the complementary slackness condition). Then, the optimal solution will be stem:[\mathbf{x}^* = \mathbf{P}^{-1}\mathbf{q}].

Sometimes we may not be able to simplify the conditions further, look for special cases, and derive the optimal solution. However, the KKT conditions are always useful for giving certificates for optimality. If someone claims that stem:[\mathbf{x}^*] is an optimal solution, we can use the KKT conditions to verify it because the optimal point should necessarily satisfy the KKT conditions.





