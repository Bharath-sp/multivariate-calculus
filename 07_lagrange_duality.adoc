= Lagrange Duality =
:doctype: book
:author: Bharath Kumar S P
:email: bharath030195@gmail.com
:stem: latexmath
:eqnums:
:toc:

== Lagrangian ==
Suppose we have a mathematical program

[stem]
++++
\begin{align*}
\min_{\mathbf{x} \in D} & \hspace{1cm} f(\mathbf{x}) \\
& \text{ s.t. } g(\mathbf{x}) \leq 0
\end{align*}
++++

This is a constrained optimization problem. We can send the constraint to the objective function and write an equivalent MP. Our feasibility set should be simpler.

Let's introduce an indicator function on a set stem:[S].

[stem]
++++
I_S(\mathbf{x}) = \begin{cases} 0 & \text{ if } \mathbf{x} \in S \\ \infty & \text{ if } \mathbf{x} \not \in S  \end{cases} 
++++

Then can rewrite our MP as

[stem]
++++
\min_{\mathbf{x} \in D} f(\mathbf{x}) + I_{\{\mathbf{x} \, | \, g(\mathbf{x}) \leq 0\}} (\mathbf{x})
++++

* If stem:[\mathbf{x} \in S], then the MP is stem:[\min_{\mathbf{x} \in D} f(\mathbf{x})].The value of the MP for such stem:[\mathbf{x}] is some finite number.
* If stem:[\mathbf{x} \not \in S], then the MP is stem:[\min_{\mathbf{x} \in D} \infty]. The value of the MP for such stem:[\mathbf{x}] is stem:[\infty]. So we can safely ignore such stem:[\mathbf{x}] for our MP.

This indicator function itself can be written as a mathematical program.

[stem]
++++
I_{\{\mathbf{x} \, | \, g(\mathbf{x}) \leq 0\}} (\mathbf{x}) = \max_{\lambda \geq 0} \lambda g(\mathbf{x})
++++

* If stem:[\mathbf{x}] is such that stem:[g(\mathbf{x}) \leq 0], say stem:[g(\mathbf{x}) = -3], then we have stem:[\max_{\lambda \geq 0} -3\lambda = 0].
* If stem:[\mathbf{x}] is such that stem:[g(\mathbf{x}) > 0], say stem:[g(\mathbf{x}) = 3], then we have stem:[\max_{\lambda \geq 0} 3\lambda = \infty].

Thus we get back our indicator function. The stem:[\lambda]'s are known as *Lagrange Multipliers*.

[NOTE]
====
[stem]
++++
\begin{align*}
I_{\{\mathbf{x} \, | \, g(\mathbf{x}) > 0\}} (\mathbf{x}) = I_{\{\mathbf{x} \, | \, - g(\mathbf{x}) \leq 0\}} (\mathbf{x}) & = \max_{\lambda \leq 0} \lambda g(\mathbf{x}) \\
I_{\{\mathbf{x} \, | \, g(\mathbf{x}) = 0\}} (\mathbf{x}) & = \max_{\lambda \in \mathbb{R}} \lambda g(\mathbf{x}) \\
\end{align*}
++++
====

Then can rewrite our MP as

[stem]
++++
\begin{align*}
& \min_{\mathbf{x} \in D} f(\mathbf{x}) + \max_{\lambda \geq 0} \lambda g(\mathbf{x}) \\
& = \min_{\mathbf{x} \in D} \max_{\lambda \geq 0} f(\mathbf{x}) + \lambda g(\mathbf{x})
\end{align*}
++++

When we have more constraints

[stem]
++++
\begin{align*}
\min_{\mathbf{x} \in D} & \hspace{1cm} f(\mathbf{x}) \\
& \text{ s.t. } g_1(\mathbf{x}) \leq 0, \dots, g_m(\mathbf{x}) \leq 0
\end{align*}
++++

Then we add one indicator for each constraint. Then this MP can be rewritten as an unconstrained optimization problem as

[stem]
++++
\begin{align*}
& \min_{\mathbf{x} \in D} f(\mathbf{x}) + I_{\{\mathbf{x} \, | \, g_1(\mathbf{x}) \leq 0\}} (\mathbf{x}) + \dots + I_{\{\mathbf{x} \, | \, g_m(\mathbf{x}) \leq 0\}} (\mathbf{x}) \\
& = \min_{\mathbf{x} \in D} f(\mathbf{x}) + \sum_{i=1}^m I_{\{\mathbf{x} \, | \, g_i(\mathbf{x}) \leq 0\}} (\mathbf{x}) \\
& = \min_{\mathbf{x} \in D} f(\mathbf{x}) + \sum_{i=1}^m \max_{\lambda_i \geq 0} \lambda_i g_i(\mathbf{x}) \\
& = \min_{\mathbf{x} \in D} \max_{\lambda_i \geq 0} f(\mathbf{x}) + \sum_{i=1}^m  \lambda_i g_i(\mathbf{x})  \\
& \geq \max_{\lambda_i \geq 0} \min_{\mathbf{x} \in D} f(\mathbf{x}) + \sum_{i=1}^m  \lambda_i g_i(\mathbf{x})\\
\end{align*}
++++

Let's denote stem:[f(\mathbf{x}) + \sum_{i=1}^m  \lambda_i g_i(\mathbf{x}) = \mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})]. This is known as the *Lagrangian function*.

The last inequality is from our previous result. For this we first evaluate the inner `min` MP. The variable of this MP is stem:[\mathbf{x}] and stem:[\lambda_i]'s are parameters. Thus the value of the MP is a function of stem:[\boldsymbol{\lambda} \in \mathbb{R}^m]. Let's denote this as stem:[\underline{\mathcal{L}}(\boldsymbol{\lambda})]. This is known as *Lagrange dual function*.

[stem]
++++
\underline{\mathcal{L}}(\boldsymbol{\lambda}) = \min_{\mathbf{x} \in D} \mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})
++++

We can see that stem:[\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda})] is a linear function in stem:[\boldsymbol{\lambda}]. Let stem:[\mathbf{x}_0] be some point in stem:[D]. For a given stem:[\mathbf{x}_0], let's plot the function stem:[\underline{\mathcal{L}}(\boldsymbol{\lambda})] as a function of stem:[\boldsymbol{\lambda}]. Then stem:[\mathcal{L}(\mathbf{x}_0, \boldsymbol{\lambda}) = f(\mathbf{x}_0) + \sum_{i=1}^m  \lambda_i g_i(\mathbf{x}_0)].

For each stem:[\mathbf{x} \in D], we get a hyperplane. Then the lagrange dual function at stem:[\boldsymbol{\lambda}_0] is the minimum of all those hyperplane values at stem:[\boldsymbol{\lambda}_0]. When we look at the minimum at every stem:[\boldsymbol{\lambda}], we trace a concave function. This happens irrespective of how the hyperplanes are.

====
stem:[\underline{\mathcal{L}}(\boldsymbol{\lambda})] is always a concave function irrespective of how terrible the functions stem:[f(\mathbf{x})] and stem:[g_i(\mathbf{x})] are. Then we solve the MP stem:[\max_{\boldsymbol{\lambda} \geq 0} \underline{\mathcal{L}}(\boldsymbol{\lambda})] which is always a convex programming problem. Solving this MP give us the *lower bound* for our original MP.

This MP is known as the Lagrange dual. There are a huge class of problems where the dual is exactly the same as the primal problem. For such problems, we can solve for the dual MP rather than the primal MP as the dual MP is often easy and tractable problem to solve.
====

In one-dimensional functions and when we have only one constraint

image::.\images\lagrangian_01.png[align='center', 500, 300]

And we are interested in finding the maximum value of this concave function.

== Examples ==

Suppose the MP is stem:[\min_{\|\mathbf{w}\| \leq 1} \mathbf{w}^\top\mathbf{x}]. This can be equivalently written as

[stem]
++++
\begin{align*}
\min_{\mathbf{w} \in \mathbb{R}^n} & \hspace{1cm} \mathbf{w}^\top\mathbf{x} \\
& \text{ s.t. } \frac{1}{2} \|\mathbf{w}\|^2  - \frac{1}{2}  \leq 0
\end{align*}
++++

We write

[stem]
++++
\begin{align*}
\mathcal{L}(\mathbf{w}, \lambda) & = \mathbf{w}^\top\mathbf{x} + \lambda \left( \frac{1}{2} \|\mathbf{w}\|^2  - \frac{1}{2}\right) \\
\underline{\mathcal{L}}(\lambda) & = \min_{\mathbf{w} \in \mathbb{R}^n} \mathcal{L}(\mathbf{w}, \lambda)
\end{align*}
++++

stem:[\mathcal{L}(\mathbf{w}, \lambda)] is a quadratic function in stem:[\mathbf{w}]. We can complete the squares and write it as

[stem]
++++
\mathcal{L}(\mathbf{w}, \lambda) = \frac{\lambda}{2} \| \mathbf{w} + \frac{\mathbf{x}}{\lambda} \|^2 -\frac{\lambda}{2} - \frac{\| \mathbf{x}\|^2}{2\lambda}
++++

(assuming stem:[\lambda \ne 0]). When stem:[\lambda=0 \implies \mathcal{L}(\mathbf{w}, \lambda) = \mathbf{w}^\top\mathbf{x} \implies \underline{\mathcal{L}}(0) = \min_{\mathbf{w} \in \mathbb{R}^n} \mathbf{w}^\top\mathbf{x} = -\infty]. Because the dot product of two vectors will be the least when they are in the opposite direction. We can take stem:[\mathbf{w}] as the negative of stem:[\mathbf{x}] and increase the magnitude. As we are interested in the maximum value of the lagrange dual function, we can safely ignore the possibility that stem:[\lambda=0].

The minimum value of this function with respect to stem:[\mathbf{w}] occurs at stem:[\mathbf{w}^* = \frac{-\mathbf{x}}{\lambda^*}] and the minimum value is stem:[-\frac{\lambda}{2} - \frac{\| \mathbf{x}\|^2}{2\lambda}]. Thus

[stem]
++++
\underline{\mathcal{L}}(\lambda) = -\frac{\lambda}{2} - \frac{\| \mathbf{x}\|^2}{2\lambda}
++++

Now we need to solve

[stem]
++++
\max_{\lambda > 0} -\frac{\lambda}{2} - \frac{\| \mathbf{x}\|^2}{2\lambda} = - \min_{\lambda > 0} \frac{\lambda}{2} + \frac{\| \mathbf{x}\|^2}{2\lambda}
++++ 

Since the feasibility set is an open set here, the necessary condition for obtaining a local minima is that the derivative of the function has to be 0. Let stem:[h(\lambda) = \frac{\lambda}{2} + \frac{\| \mathbf{x}\|^2}{2\lambda}]. The derivative of this one-dimensional variable function is

[stem]
++++
\begin{align*}
h'(\lambda) & = 0 \\
\frac{1}{2} + \frac{\| \mathbf{x}\|^2}{2} \left( \frac{-1}{\lambda^2} \right) & = 0 \iff \lambda^* = \| \mathbf{x}\|
\end{align*}
++++

This point can be a local minima or local maxima. Let's check the sign of the double derivative. stem:[h''(\lambda) = \frac{\| \mathbf{x}\|^2}{\lambda^3}]. As stem:[\mathbf{x}] is not a zero vector and stem:[\lambda > 0], this quantity is always stem:[>0]. This confirms that the function stem:[h(\lambda)] is a convex function.

Thus the optimal solution is stem:[\lambda^* = \| \mathbf{x}\|] and stem:[\mathbf{w}^* = \frac{-\mathbf{x}}{\| \mathbf{x}\|}].





